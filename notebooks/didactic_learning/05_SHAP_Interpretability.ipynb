{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Módulo 5: La Caja de Cristal (Interpretability & SHAP)\n",
                "\n",
                "## Objetivo Didáctico\n",
                "Convertir nuestro potente XGBoost (Caja Negra) en una **Caja de Cristal**. Usaremos **SHAP** (SHapley Additive exPlanations), una técnica ganadora del Premio Nobel de Economía (Teoría de Juegos), para explicar CADA predicción.\n",
                "\n",
                "## 1. Preparando el Modelo\n",
                "Primero, entrenamos nuestro XGBoost como siempre."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instalar SHAP si no lo tienes\n",
                "!pip install shap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import xgboost as xgb\n",
                "import shap\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Cargar datos\n",
                "df = pd.read_csv('../../data/processed/clean_student_data.csv')\n",
                "df_binary = df[df['Target'].isin(['Dropout', 'Graduate'])].copy()\n",
                "df_binary['Target_Binary'] = df_binary['Target'].apply(lambda x: 1 if x == 'Dropout' else 0)\n",
                "\n",
                "features = [\n",
                "    'Curricular units 1st sem (grade)', \n",
                "    'Age at enrollment', \n",
                "    'Tuition fees up to date', \n",
                "    'Scholarship holder', \n",
                "    'Debtor'\n",
                "]\n",
                "\n",
                "X = df_binary[features]\n",
                "y = df_binary['Target_Binary']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
                "\n",
                "# Entrenar XGBoost\n",
                "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
                "model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Encendiendo la Luz (SHAP)\n",
                "SHAP calcula cuánto contribuyó cada variable a la predicción, comparado con el promedio."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inicializar JS para gráficos interactivos (si corres esto en local)\n",
                "shap.initjs()\n",
                "\n",
                "# Crear el explicador\n",
                "explainer = shap.Explainer(model)\n",
                "shap_values = explainer(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Explicación Global (Resumen)\n",
                "Este gráfico es **mucho mejor** que el de \"Importancia de Variables\" clásico.\n",
                "*   **Color Rojo**: Valor alto de la variable (ej. Nota Alta).\n",
                "*   **Color Azul**: Valor bajo de la variable (ej. Nota Baja).\n",
                "*   **Lado Derecho**: Aumenta el riesgo de Dropout.\n",
                "*   **Lado Izquierdo**: Disminuye el riesgo (Protege)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "shap.summary_plot(shap_values, X_test, show=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Lectura\n",
                "Mira `Curricular units 1st sem (grade)`:\n",
                "*   Los puntos **Rojos** (Notas Altas) están a la **Izquierda** (Bajan el riesgo).\n",
                "*   Los puntos **Azules** (Notas Bajas) están a la **Derecha** (Suben el riesgo).\n",
                "\n",
                "¡Ahora sí sabemos la dirección del impacto!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Explicación Local (Caso Individual)\n",
                "¿Por qué el Estudiante #5 tiene un riesgo alto? Vamos a verlo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Elegimos un estudiante al azar (índice 5)\n",
                "idx = 5\n",
                "shap.plots.waterfall(shap_values[idx])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Lectura del Waterfall\n",
                "*   **E[f(x)]**: Es el riesgo promedio de todos los alumnos (ej. 0.5).\n",
                "*   **Barras Rojas**: Factores que empujaron su riesgo hacia arriba.\n",
                "*   **Barras Azules**: Factores que lo empujaron hacia abajo.\n",
                "*   **f(x)**: Es su riesgo final.\n",
                "\n",
                "Esto te permite decirle a un directivo: \"Este alumno tiene riesgo porque debe la matrícula (+20%) y reprobó el semestre (+15%), aunque su beca le ayudó un poco (-5%)\"."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusión Final\n",
                "Hemos completado el viaje:\n",
                "1.  **Regresión Logística**: Entendimos la base.\n",
                "2.  **Árboles**: Entendimos las decisiones lógicas.\n",
                "3.  **Random Forest**: Entendimos la estabilidad.\n",
                "4.  **XGBoost**: Conseguimos la máxima potencia.\n",
                "5.  **SHAP**: Recuperamos la explicabilidad.\n",
                "\n",
                "¡Estás listo para tu Tesis!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}