```json
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Fase 3: Modelado, Evaluaci贸n e Interpretaci贸n\n",
    "\n",
    "**Objetivo:** Entrenar el modelo final con los hiperpar谩metros optimizados, evaluarlo con m茅tricas profesionales y entender qu茅 caracter铆sticas son las m谩s influyentes en sus predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Carga y Preparaci贸n Final de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Carga los datos que ya procesaste\n",
    "print(\"Cargando datos preprocesados...\")\n",
    "df_processed = pd.read_parquet('../data/processed/preprocessed_data.parquet')\n",
    "\n",
    "# Define tus features (X) y tu target (y)\n",
    "X = df_processed.drop('Target', axis=1)\n",
    "y_raw = df_processed['Target']\n",
    "\n",
    "# Codificar la variable objetivo (Target) a valores num茅ricos\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_raw)\n",
    "\n",
    "# Guardar las clases para usarlas en las visualizaciones\n",
    "class_names = label_encoder.classes_\n",
    "print(f\"Clases codificadas: {dict(zip(class_names, range(len(class_names))))}\")\n",
    "\n",
    "# Convertir todas las columnas de X a tipos de datos que XGBoost entiende (evitar errores)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Divide en entrenamiento y prueba (隆usa stratify!)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Datos listos. Formas: X_train={X_train.shape}, X_test={X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Modelo Final (Entrenamiento con los Mejores Hiperpar谩metros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Inicializa el modelo con los MEJORES par谩metros que ya encontraste\n",
    "best_params = {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
    "\n",
    "# Para problemas multiclase, el objetivo y la m茅trica cambian\n",
    "model_final = XGBClassifier(\n",
    "    objective='multi:softprob',  # Objetivo para clasificaci贸n multiclase\n",
    "    num_class=len(class_names),    # N煤mero de clases a predecir\n",
    "    eval_metric='mlogloss',        # M茅trica de evaluaci贸n para multiclase\n",
    "    use_label_encoder=False,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "# Entrena el modelo final\n",
    "print(\"Entrenando el modelo final con los mejores hiperpar谩metros...\")\n",
    "model_final.fit(X_train, y_train)\n",
    "print(\"隆Modelo final entrenado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Evaluaci贸n Profesional del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Realiza predicciones en el conjunto de prueba\n",
    "y_pred = model_final.predict(X_test)\n",
    "y_pred_proba = model_final.predict_proba(X_test) # Probabilidades para cada clase\n",
    "\n",
    "# --- 1. Classification Report --- "",
    "print(\"--- Classification Report ---\")\n",
    "report = classification_report(y_test, y_pred, target_names=class_names)\n",
    "print(report)\n",
    "\n",
    "# --- 2. Matriz de Confusi贸n --- "",
    "print(\"\n--- Matriz de Confusi贸n ---\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicci贸n')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('Matriz de Confusi贸n - Modelo Final')\n",
    "plt.savefig('../app/static/imagenes/7_matriz_confusion.png') # Guarda el Exhibit\n",
    "plt.show()\n",
    "\n",
    "# --- 3. Curva ROC y AUC (para multiclase, se hace One-vs-Rest) --- "",
    "print(\"\n--- Curva ROC y AUC (One-vs-Rest) ---\")\n",
    "\n",
    "# Calcular AUC para cada clase\n",
    "roc_auc_ovr = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average=None)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f'AUC para la clase \'{class_name}\'': {roc_auc_ovr[i]:.4f}')\n",
    "\n",
    "# Calcular AUC promedio ponderado\n",
    "roc_auc_avg = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')\n",
    "print(f'\nAUC Promedio Ponderado (OvR): {roc_auc_avg:.4f}')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i, color in zip(range(len(class_names)), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, i], pos_label=i)\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'Curva ROC de {class_names[i]} (AUC = {roc_auc_ovr[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC Multiclase (One-vs-Rest)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('../app/static/imagenes/8_curva_roc.png') # Guarda el Exhibit\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Interpretaci贸n Final (Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [