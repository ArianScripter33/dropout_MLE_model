{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Modelado Final: XGBoost Optimizado para Predicción de Abandono Estudiantil\n",
    "\n",
    "Este notebook implementa el modelo final de XGBoost con hiperparámetros optimizados, evaluación profesional (Classification Report, Matriz de Confusión, Curva ROC y AUC) e interpretación de features.\n",
    "\n",
    "### Objetivos:\n",
    "- Entrenar el modelo final con los mejores hiperparámetros.\n",
    "- Evaluarlo con métricas robustas para validar el rendimiento (NFR-01).\n",
    "- Generar visualizaciones y Exhibits para el informe.\n",
    "- Interpretar qué features son clave para las predicciones (FR-03).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Configuración para gráficos\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Carga y Preparación de Datos\n",
    "\n",
    "Cargamos los datos procesados, binarizamos la variable objetivo para enfocarnos en abandono y dividimos en train/test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos procesados\n",
    "df = pd.read_parquet('../data/processed/preprocessed_data.parquet')\n",
    "\n",
    "# Definir features (X) y target (y)\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# Binarizar y: 1 si 'Dropout', 0 si no (para enfocarnos en abandono)\n",
    "y = y.apply(lambda x: 1 if x == 'Dropout' else 0)\n",
    "\n",
    "# Label encoding para convertir a numérico\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Dividir en train y test con estratificación\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Datos cargados: {df.shape}')\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')\n",
    "print(f'Balance de clases en train: {pd.Series(y_train).value_counts(normalize=True)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Entrenamiento del Modelo Final\n",
    "\n",
    "Usamos los mejores hiperparámetros encontrados en la optimización previa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejores hiperparámetros encontrados\n",
    "best_params = {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
    "\n",
    "# Instanciar y entrenar el modelo final (binario para abandono)\n",
    "model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Modelo final entrenado exitosamente.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Evaluación Profesional del Modelo\n",
    "\n",
    "Calculamos métricas clave: Classification Report, Matriz de Confusión, Curva ROC y AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en el conjunto de test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probabilidades para ROC\n",
    "\n",
    "# 1. Classification Report\n",
    "print('--- Classification Report ---')\n",
    "report = classification_report(y_test, y_pred, target_names=['No Dropout', 'Dropout'])\n",
    "print(report)\n",
    "\n",
    "# 2. Matriz de Confusión\n",
    "print('\\n--- Matriz de Confusión ---')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Dropout', 'Dropout'], yticklabels=['No Dropout', 'Dropout'])\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('Matriz de Confusión - Modelo Final')\n",
    "plt.savefig('../exhibits/matriz_confusion.png')  # Guarda el Exhibit\n",
    "plt.show()\n",
    "\n",
    "# 3. Curva ROC y AUC\n",
    "print('\\n--- Curva ROC y AUC ---')\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'Área Bajo la Curva (AUC): {roc_auc:.4f}')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - Modelo Final')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('../exhibits/curva_roc.png')  # Guarda el Exhibit\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Interpretación del Modelo (Feature Importance)\n",
    "\n",
    "Extraemos y visualizamos las características más importantes del modelo final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Top 15 features\n",
    "top_features = feature_importances.head(15)\n",
    "\n",
    "print('--- Top 15 Características Más Importantes ---')\n",
    "print(top_features)\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "plt.title('Top 15 Características Más Importantes - Modelo Final')\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Característica')\n",
    "plt.savefig('../exhibits/feature_importance.png')  # Guarda el Exhibit\n",
    "plt.show()\n",
    "\n",
    "# Interpretación breve\n",
    "print('\\n--- Interpretación ---')\n",
    "print(f'La característica más importante es \"{top_features.iloc[0][\"Feature\"]}\" con importancia {top_features.iloc[0][\"Importance\"]:.4f}.')\n",
    "print('Esto indica que factores como el rendimiento académico y financieros son clave para predecir abandonos.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones Finales\n",
    "\n",
    "- **Rendimiento del Modelo:** Revisa el AUC y F1-Score. Un AUC >0.8 indica un modelo sólido para distinguir entre graduados y desertores.\n",
    "- **Exhibits Generados:** Los gráficos se guardaron en `../exhibits/` para tu informe.\n",
    "- **Próximos Pasos:** Usa estos resultados para validar NFR-01 y explicar el modelo en tu presentación.\n",
    "\n",
    "¡Ejecuta las celdas en orden y listo!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
