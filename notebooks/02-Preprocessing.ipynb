{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Preprocesamiento de Datos y Ingenier\u00eda de Caracter\u00edsticas\n## \ud83d\udcca Fase 2: Preparaci\u00f3n de Datos para Modelado\n\n**Objetivo:** Transformar los datos crudos en un formato adecuado para el entrenamiento de modelos de Machine Learning.\n\n**Tareas principales:**\n- Limpieza y manejo de valores faltantes\n- Codificaci\u00f3n de variables categ\u00f3ricas\n- Escalado y normalizaci\u00f3n de caracter\u00edsticas num\u00e9ricas\n- Ingenier\u00eda de nuevas caracter\u00edsticas (feature engineering)\n- Divisi\u00f3n del dataset en conjuntos de entrenamiento, validaci\u00f3n y prueba\n- Manejo del desbalanceo de clases\n\n---\n\n## \ud83d\udccb 1. Carga de Datos y Configuraci\u00f3n Inicial\n\nVamos a cargar los datos preprocesados y configurar el entorno de trabajo."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configuraci\u00f3n de estilo\nsns.set_style(\"whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (12, 8)\n\n# Cargar datos\nprint(\"\ud83d\ude80 Iniciando preprocesamiento de datos...\")\ntry:\n    df = pd.read_csv(\"../data/raw/data.csv\", sep=\";\")\n    print(f\"\u2705 Datos cargados exitosamente: {df.shape}\")\nexcept FileNotFoundError:\n    print(\"\u274c Error: No se encontr\u00f3 el archivo data.csv\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \ud83d\udd0d 2. An\u00e1lisis Inicial y Limpieza de Datos\n\nPrimero vamos a explorar los datos para identificar problemas y planificar la limpieza."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Informaci\u00f3n general del dataset\nprint(\"\ud83d\udcca Informaci\u00f3n del dataset:\")\nprint(f\"N\u00famero de filas: {df.shape[0]}\")\nprint(f\"N\u00famero de columnas: {df.shape[1]}\")\nprint(f\"Tipos de datos:\n{df.dtypes.value_counts()}\")\n\n# Valores faltantes\nprint(\"\n\ud83d\udea8 Valores faltantes por columna:\")\nmissing_values = df.isnull().sum()\nprint(missing_values[missing_values > 0])\n\n# Estad\u00edsticas b\u00e1sicas\nprint(\"\n\ud83d\udcc8 Estad\u00edsticas descriptivas:\")\nprint(df.describe())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \ud83e\uddf9 3. Limpieza de Datos y Manejo de Valores Faltantes\n\nVamos a limpiar los datos y manejar los valores faltantes apropiadamente."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Crear copia del dataset para preprocesamiento\ndf_processed = df.copy()\n\n# 1. Verificar valores faltantes\nprint(\"Valores faltantes antes de limpieza:\")\nprint(df_processed.isnull().sum().sum())\n\n# 2. Estrategias de manejo de valores faltantes:\n# Para variables num\u00e9ricas: usar mediana (m\u00e1s robusta que la media)\n# Para variables categ\u00f3ricas: usar moda o crear categor\u00eda 'Desconocido'\n\nnumeric_cols = df_processed.select_dtypes(include=[np.number]).columns\ncategorical_cols = df_processed.select_dtypes(exclude=[np.number]).columns\n\nprint(f\"Columnas num\u00e9ricas: {len(numeric_cols)}\")\nprint(f\"Columnas categ\u00f3ricas: {len(categorical_cols)}\")\n\n# Imputaci\u00f3n para columnas num\u00e9ricas\nfor col in numeric_cols:\n    if df_processed[col].isnull().sum() > 0:\n        median_value = df_processed[col].median()\n        df_processed[col].fillna(median_value, inplace=True)\n        print(f\"\u2705 Imputada columna num\u00e9rica '{col}' con mediana: {median_value:.2f}\")\n\n# Imputaci\u00f3n para columnas categ\u00f3ricas\nfor col in categorical_cols:\n    if df_processed[col].isnull().sum() > 0:\n        mode_value = df_processed[col].mode().iloc[0] if not df_processed[col].mode().empty else 'Desconocido'\n        df_processed[col].fillna(mode_value, inplace=True)\n        print(f\"\u2705 Imputada columna categ\u00f3rica '{col}' con moda: {mode_value}\")\n\nprint(f\"\n\u2705 Valores faltantes despu\u00e9s de limpieza: {df_processed.isnull().sum().sum()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \ud83c\udff7\ufe0f 4. Codificaci\u00f3n de Variables Categ\u00f3ricas\n\nLas variables categ\u00f3ricas necesitan ser transformadas a formato num\u00e9rico para los modelos de ML."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Separar caracter\u00edsticas y variable objetivo\nfeature_cols = [col for col in df_processed.columns if col != 'Target']\ntarget_col = 'Target'\n\nX = df_processed[feature_cols]\ny = df_processed[target_col]\n\n# Identificar tipos de columnas para preprocessing\nnumeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\ncategorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n\nprint(f\"Caracter\u00edsticas num\u00e9ricas: {len(numeric_features)}\")\nprint(f\"Caracter\u00edsticas categ\u00f3ricas: {len(categorical_features)}\")\n\n# Crear preprocesador\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numeric_features),\n        ('cat', OneHotEncoder(drop='first', sparse=False), categorical_features)\n    ],\n    remainder='passthrough'\n)\n\nprint(\"\n\ud83d\udd27 Preprocesador creado exitosamente\")\nprint(f\"Total de caracter\u00edsticas despu\u00e9s de encoding: {len(numeric_features) + len(categorical_features)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \u2696\ufe0f 5. Manejo del Desbalanceo de Clases\n\nVamos a analizar si hay desbalanceo significativo en la variable objetivo y aplicar t\u00e9cnicas apropiadas."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analizar distribuci\u00f3n de clases\nprint(\"\ud83d\udcca Distribuci\u00f3n de clases objetivo:\")\nclass_distribution = y.value_counts()\nprint(class_distribution)\n\n# Calcular porcentajes\nclass_percentages = (class_distribution / len(y)) * 100\nprint(f\"\nPorcentajes:\n{class_percentages}\")\n\n# Visualizar distribuci\u00f3n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(class_distribution.index, class_distribution.values,\n               color=['red', 'green', 'blue'])\nplt.title('Distribuci\u00f3n de Clases - Variable Objetivo')\nplt.xlabel('Clases')\nplt.ylabel('N\u00famero de Muestras')\nplt.xticks(rotation=45)\n\n# Agregar etiquetas con porcentajes\nfor bar, percentage in zip(bars, class_percentages):\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 50,\n             f'{percentage:.1f}%', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n# Evaluar si hay desbalanceo significativo\nmin_class_ratio = class_distribution.min() / class_distribution.max()\nprint(f\"\n\ud83d\udccf Ratio de desbalanceo (min/max): {min_class_ratio:.3f}\")\n\nif min_class_ratio < 0.8:  # Si hay desbalanceo significativo\n    print(\"\u26a0\ufe0f Se detecta desbalanceo significativo de clases\")\n    print(\"\ud83d\udca1 Recomendaciones:\")\n    print(\"   - Usar t\u00e9cnicas de oversampling (SMOTE) para clases minoritarias\")\n    print(\"   - Usar t\u00e9cnicas de undersampling para clases mayoritarias\")\n    print(\"   - Usar m\u00e9tricas de evaluaci\u00f3n que manejen desbalanceo (F1-score, AUC-ROC)\")\n    print(\"   - Considerar usar class_weight='balanced' en modelos que lo soporten\")\nelse:\n    print(\"\u2705 Las clases est\u00e1n razonablemente balanceadas\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \u2702\ufe0f 6. Divisi\u00f3n del Dataset\n\nVamos a dividir los datos en conjuntos de entrenamiento, validaci\u00f3n y prueba."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Estratificar por la variable objetivo para mantener distribuci\u00f3n de clases\nX_train, X_temp, y_train, y_temp = train_test_split(\n    X, y,\n    test_size=0.3,  # 70% entrenamiento, 30% temporal\n    random_state=42,\n    stratify=y  # Mantener proporci\u00f3n de clases\n)\n\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp,\n    test_size=0.5,  # 50% de los datos temporales para validaci\u00f3n y prueba\n    random_state=42,\n    stratify=y_temp  # Mantener proporci\u00f3n en el split\n)\n\nprint(f\"\ud83d\udcca Divisi\u00f3n del dataset:\")\nprint(f\"   Entrenamiento: {X_train.shape[0]} muestras ({X_train.shape[0]/len(df)*100:.1f}%)\")\nprint(f\"   Validaci\u00f3n: {X_val.shape[0]} muestras ({X_val.shape[0]/len(df)*100:.1f}%)\")\nprint(f\"   Prueba: {X_test.shape[0]} muestras ({X_test.shape[0]/len(df)*100:.1f}%)\")\nprint(f\"\nVerificaci\u00f3n de estratificaci\u00f3n:\")\n\n# Verificar que las proporciones se mantienen\nfor split_name, split_y in [(\"Entrenamiento\", y_train), (\"Validaci\u00f3n\", y_val), (\"Prueba\", y_test)]:\n    print(f\"   {split_name}: {split_y.value_counts().to_dict()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \ud83d\ude80 7. Aplicaci\u00f3n del Preprocesamiento Completo\n\nAhora vamos a aplicar todo el pipeline de preprocesamiento a nuestros conjuntos de datos."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aplicar preprocesamiento a los conjuntos de datos\nprint(\"\ud83d\udd04 Aplicando preprocesamiento...\")\n\nX_train_processed = preprocessor.fit_transform(X_train)\nX_val_processed = preprocessor.transform(X_val)\nX_test_processed = preprocessor.transform(X_test)\n\n# Obtener nombres de caracter\u00edsticas despu\u00e9s del encoding\nfeature_names = (numeric_features +\n                preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist())\n\nprint(f\"\u2705 Caracter\u00edsticas originales: {X_train.shape[1]}\")\nprint(f\"\u2705 Caracter\u00edsticas procesadas: {X_train_processed.shape[1]}\")\nprint(f\"\ud83d\udcca Forma de los conjuntos procesados:\")\nprint(f\"   X_train: {X_train_processed.shape}\")\nprint(f\"   X_val: {X_val_processed.shape}\")\nprint(f\"   X_test: {X_test_processed.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \ud83d\udcbe 8. Guardado de Datos Preprocesados\n\nFinalmente, vamos a guardar los conjuntos de datos preprocesados para usarlos en el modelado."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Crear DataFrames procesados\ntrain_processed = pd.DataFrame(X_train_processed, columns=feature_names)\ntrain_processed['Target'] = y_train.reset_index(drop=True)\n\nval_processed = pd.DataFrame(X_val_processed, columns=feature_names)\nval_processed['Target'] = y_val.reset_index(drop=True)\n\ntest_processed = pd.DataFrame(X_test_processed, columns=feature_names)\ntest_processed['Target'] = y_test.reset_index(drop=True)\n\n# Guardar conjuntos procesados\noutput_dir = \"../data/processed/\"\n\ntry:\n    train_processed.to_csv(f\"{output_dir}train_processed.csv\", index=False)\n    val_processed.to_csv(f\"{output_dir}val_processed.csv\", index=False)\n    test_processed.to_csv(f\"{output_dir}test_processed.csv\", index=False)\n    \n    print(\"\ud83d\udcbe Datos procesados guardados exitosamente:\")\n    print(f\"   \u2705 train_processed.csv: {train_processed.shape}\")\n    print(f\"   \u2705 val_processed.csv: {val_processed.shape}\")\n    print(f\"   \u2705 test_processed.csv: {test_processed.shape}\")\n    \n    # Guardar informaci\u00f3n del preprocesamiento\n    preprocessing_info = {\n        'numeric_features': numeric_features,\n        'categorical_features': categorical_features,\n        'feature_names': feature_names,\n        'class_distribution': class_distribution.to_dict(),\n        'dataset_shapes': {\n            'original': df.shape,\n            'train': X_train_processed.shape,\n            'val': X_val_processed.shape,\n            'test': X_test_processed.shape\n        }\n    }\n    \n    import json\n    with open(f\"{output_dir}preprocessing_info.json\", 'w') as f:\n        json.dump(preprocessing_info, f, indent=2)\n    \n    print(f\"\u2705 Informaci\u00f3n de preprocesamiento guardada en preprocessing_info.json\")\n    \nexcept Exception as e:\n    print(f\"\u274c Error al guardar archivos: {e}\")\n    print(\"\ud83d\udca1 Crea el directorio ../data/processed/ si no existe\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \ud83d\udccb 9. Resumen del Preprocesamiento\n\nVamos a crear un resumen completo del proceso de preprocesamiento realizado."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\ud83c\udf89 PREPROCESAMIENTO COMPLETADO\")\nprint(\"=\" * 50)\nprint(f\"\ud83d\udcca Datos originales: {df.shape}\")\nprint(f\"\ud83d\udcc8 Datos de entrenamiento: {X_train_processed.shape}\")\nprint(f\"\ud83d\udccb Datos de validaci\u00f3n: {X_val_processed.shape}\")\nprint(f\"\ud83e\uddea Datos de prueba: {X_test_processed.shape}\")\n\nprint(\"\n\ud83d\udd27 Transformaciones aplicadas:\")\nprint(f\"   \u2705 Valores faltantes manejados: {df.isnull().sum().sum()} \u2192 0\")\nprint(f\"   \u2705 Variables categ\u00f3ricas codificadas: {len(categorical_features)}\")\nprint(f\"   \u2705 Variables num\u00e9ricas escaladas: {len(numeric_features)}\")\nprint(f\"   \u2705 Nuevas caracter\u00edsticas creadas: {X_train_processed.shape[1] - X_train.shape[1]}\")\n\nprint(\"\n\ud83d\udccb Archivos generados:\")\nprint(\"   \ud83d\udcc1 ../data/processed/train_processed.csv\")\nprint(\"   \ud83d\udcc1 ../data/processed/val_processed.csv\")\nprint(\"   \ud83d\udcc1 ../data/processed/test_processed.csv\")\nprint(\"   \ud83d\udcc1 ../data/processed/preprocessing_info.json\")\n\nprint(\"\n\ud83d\ude80 \u00a1Listo para la siguiente fase: Modelado!\")\nprint(\"\ud83d\udca1 Los datos est\u00e1n ahora en el formato \u00f3ptimo para entrenamiento de modelos ML\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}